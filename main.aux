\relax 
\citation{catal2009systematic}
\citation{jiang2013personalized}
\citation{nam2014survey}
\citation{maurice1977elements}
\citation{mccabe1976complexity}
\citation{wang2018deep}
\citation{wang2018deep}
\citation{zhou2018far}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}\protected@file@percent }
\citation{whua2020fcca}
\citation{wang2018deep}
\citation{fan2019deep}
\citation{li2017software}
\citation{hinton2006fast}
\citation{fan2019deep}
\citation{li2017software}
\citation{mikolov2013distributed}
\citation{pennington2014glove}
\@writefile{toc}{\contentsline {section}{\numberline {II}Background}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Code Representation}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Deep belief network and word embedding in software defect prediction}{2}\protected@file@percent }
\citation{hochreiter1997long}
\citation{fan2019deep}
\citation{liang2019seml}
\citation{liu2018connecting}
\citation{zhou2018far}
\citation{wang2018gated}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-C}}Recurrent Neural Network in software defect prediction}{3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces LSTM model}}{3}\protected@file@percent }
\newlabel{fig2}{{1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-D}}Motivation}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {III}Approach}{3}\protected@file@percent }
\newlabel{approach}{{III}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Data preprocessing}{3}\protected@file@percent }
\newlabel{data_preprocessing}{{\unhbox \voidb@x \hbox {III-A}}{3}}
\citation{wang2018deep}
\citation{fan2019deep}
\citation{ni2019empirical}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces A concrete example}}{4}\protected@file@percent }
\newlabel{fig1}{{2}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces GH-LSTMs}}{4}\protected@file@percent }
\newlabel{fig3}{{3}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Hierarchical LSTMs}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-C}}Gated merge layer}{4}\protected@file@percent }
\citation{he2013learning}
\citation{wang2018deep}
\citation{fan2019deep}
\citation{li2017software}
\citation{he2013learning}
\citation{jing2014dictionary}
\citation{chen2020different}
\citation{wang2018deep}
\citation{fan2019deep}
\citation{wang2018deep}
\citation{liang2019seml}
\citation{fan2019deep}
\citation{jian2017dpcnn}
\citation{jiang2008techniques}
\citation{wang2018deep}
\citation{fan2019deep}
\citation{jing2014dictionary}
\citation{menzies2006data}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-D}}Model training}{5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {IV}Experiments settings}{5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Evaluated projects and datasets}{5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Baseline setting}{5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}}Evaluation}{5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}1}Metrics for non-effort-aware evaluation}{5}\protected@file@percent }
\citation{jiang2013personalized}
\citation{huang2017supervised}
\citation{kamei2012large}
\citation{wang2018deep}
\citation{zhou2018far}
\citation{huang2019revisiting}
\citation{yang2016effort}
\citation{wang2018deep}
\citation{zhou2018far}
\citation{kochhar2016practitioners}
\citation{mende2010effort}
\citation{wang2018deep}
\citation{zhou2018far}
\citation{huang2019revisiting}
\citation{yang2016effort}
\citation{fan2019deep}
\citation{liu2018connecting}
\citation{benjamini1995controlling}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Dataset description}}{6}\protected@file@percent }
\newlabel{tab1}{{I}{6}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces The selected AST nodes}}{6}\protected@file@percent }
\newlabel{tab2}{{II}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}2}Metrics for effort-aware evaluation}{6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}3}Win/Tie/Loss indicator}{6}\protected@file@percent }
\citation{wang2018deep}
\citation{fan2019deep}
\citation{jian2017dpcnn}
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces Traditional features selected from PROMISE datasets}}{7}\protected@file@percent }
\newlabel{tab3}{{III}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces An example of Alberg diagram}}{7}\protected@file@percent }
\newlabel{fig_popt}{{4}{7}}
\@writefile{lot}{\contentsline {table}{\numberline {IV}{\ignorespaces Mappings between the Cliff's delta values($|\delta |$) and their effective levels}}{7}\protected@file@percent }
\newlabel{tab_delta}{{IV}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-D}}Parameters setting}{7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {V}Experimental results}{7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-A}}Answer to RQ1: How does GH-LSTMs perform under non-effort-aware scenario?}{7}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {V}{\ignorespaces Hyper parameters for all LSTM networks used in GH-LSTMs, TRD, DBN and SCE}}{8}\protected@file@percent }
\newlabel{tab_parameters}{{V}{8}}
\@writefile{lot}{\contentsline {table}{\numberline {VI}{\ignorespaces Hyper parameters for GloVe, DBN, DP-AM and DP-CNN}}{8}\protected@file@percent }
\newlabel{tab_other_parameters}{{VI}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Overall $F-measure$ comparison of DBN, SCE, DP-AM and GH-LSTMs}}{8}\protected@file@percent }
\newlabel{fig_box_F-measure}{{5}{8}}
\@writefile{lot}{\contentsline {table}{\numberline {VII}{\ignorespaces $F-measure$ values of DBN, SCE, DP-AM and GH-LSTMs}}{9}\protected@file@percent }
\newlabel{tab_f}{{VII}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-B}}Answer to RQ2: How does GH-LSTMs perform under effort-aware scenario?}{9}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {VIII}{\ignorespaces $PofB20$ scores of DBN, SCE, DP-AM and GH-LSTMs}}{10}\protected@file@percent }
\newlabel{tab_pof}{{VIII}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Overall $PofB20$ comparison of DBN, SCE, DP-AM and GH-LSTMs}}{10}\protected@file@percent }
\newlabel{fig_box_PofB20}{{6}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Overall $IFA$ comparison of DBN, SCE, DP-AM and GH-LSTMs}}{10}\protected@file@percent }
\newlabel{fig_box_IFA}{{7}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Overall $P_{opt}$ comparison of DBN, SCE, DP-AM and GH-LSTMs}}{10}\protected@file@percent }
\newlabel{fig_box_Popt}{{8}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-C}}Answer to RQ3: How do external parameters affect the performance of GH-LSTMs?}{10}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {IX}{\ignorespaces $IFA$ of DBN, SCE, DP-AM and GH-LSTMs}}{11}\protected@file@percent }
\newlabel{tab_ifa}{{IX}{11}}
\@writefile{lot}{\contentsline {table}{\numberline {X}{\ignorespaces $P_{opt}$ scores of DBN, SCE, DP-AM and GH-LSTMs}}{11}\protected@file@percent }
\newlabel{tab_popt}{{X}{11}}
\citation{liang2019seml}
\citation{fan2019deep}
\citation{jureczko2010towards}
\citation{jureczko2010using}
\citation{wang2018deep}
\citation{liang2019seml}
\citation{fan2019deep}
\citation{phan2017convolutional}
\citation{whua2020fcca}
\citation{wang2018deep}
\citation{fan2019deep}
\citation{menzies2006data}
\citation{nagappan2010change}
\citation{nagappan2005use}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces F-measure of GH-LSTMs under different embedding dimensions}}{12}\protected@file@percent }
\newlabel{fig_dimensions}{{9}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces F-measure of GH-LSTMs under different sizes of training sets}}{12}\protected@file@percent }
\newlabel{fig_size}{{10}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Threats to validity}{12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-A}}Internal validity}{12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-B}}External validity}{12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-C}}Construct validity}{12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-D}}Conclusion validity}{12}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {VII}Related works}{12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VII-A}}Traditional software defect prediction}{12}\protected@file@percent }
\citation{elish2008predicting}
\citation{wen2012systematic}
\citation{catal2009investigating}
\citation{elish2008predicting}
\citation{ryu2016value}
\citation{yang2015deep}
\citation{kamei2007effects}
\citation{liu2018connecting}
\citation{wang2018deep}
\citation{liang2019seml}
\citation{fan2019deep}
\bibstyle{IEEEtran}
\bibdata{IEEEtran}
\bibcite{catal2009systematic}{1}
\bibcite{jiang2013personalized}{2}
\bibcite{nam2014survey}{3}
\bibcite{maurice1977elements}{4}
\bibcite{mccabe1976complexity}{5}
\bibcite{wang2018deep}{6}
\bibcite{zhou2018far}{7}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VII-B}}Deep learning in software defect prediction}{13}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {VIII}Conclusion and future work}{13}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{References}{13}\protected@file@percent }
\bibcite{whua2020fcca}{8}
\bibcite{fan2019deep}{9}
\bibcite{li2017software}{10}
\bibcite{hinton2006fast}{11}
\bibcite{mikolov2013distributed}{12}
\bibcite{pennington2014glove}{13}
\bibcite{hochreiter1997long}{14}
\bibcite{liang2019seml}{15}
\bibcite{liu2018connecting}{16}
\bibcite{wang2018gated}{17}
\bibcite{ni2019empirical}{18}
\bibcite{he2013learning}{19}
\bibcite{jing2014dictionary}{20}
\bibcite{chen2020different}{21}
\bibcite{jian2017dpcnn}{22}
\bibcite{jiang2008techniques}{23}
\bibcite{menzies2006data}{24}
\bibcite{huang2017supervised}{25}
\bibcite{kamei2012large}{26}
\bibcite{huang2019revisiting}{27}
\bibcite{yang2016effort}{28}
\bibcite{kochhar2016practitioners}{29}
\bibcite{mende2010effort}{30}
\bibcite{benjamini1995controlling}{31}
\bibcite{jureczko2010towards}{32}
\bibcite{jureczko2010using}{33}
\bibcite{phan2017convolutional}{34}
\bibcite{nagappan2010change}{35}
\bibcite{nagappan2005use}{36}
\bibcite{elish2008predicting}{37}
\bibcite{wen2012systematic}{38}
\bibcite{catal2009investigating}{39}
\bibcite{ryu2016value}{40}
\bibcite{yang2015deep}{41}
\bibcite{kamei2007effects}{42}
\@writefile{toc}{\contentsline {section}{Biographies}{15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Hao Wang}{15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Weiyuan Zhuang}{15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Xiaofang Zhang}{15}\protected@file@percent }
