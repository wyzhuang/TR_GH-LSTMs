\relax 
\citation{catal2009systematic}
\citation{jiang2013personalized}
\citation{nam2014survey}
\citation{maurice1977elements}
\citation{mccabe1976complexity}
\citation{wang2018deep}
\citation{wang2018deep}
\citation{zhou2018far}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}\protected@file@percent }
\citation{wang2018deep}
\citation{fan2019deep}
\citation{li2017software}
\citation{hinton2006fast}
\citation{fan2019deep}
\citation{li2017software}
\citation{mikolov2013distributed}
\citation{pennington2014glove}
\citation{hochreiter1997long}
\@writefile{toc}{\contentsline {section}{\numberline {II}Background}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Deep belief network and word embedding in software defect prediction}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Recurrent Neural Network in software defect prediction}{2}\protected@file@percent }
\citation{fan2019deep}
\citation{liang2019seml}
\citation{liu2018connecting}
\citation{zhou2018far}
\citation{wang2018gated}
\citation{wang2018deep}
\citation{fan2019deep}
\citation{ni2019empirical}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces LSTM model}}{3}\protected@file@percent }
\newlabel{fig2}{{1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-C}}Motivation}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {III}Approach}{3}\protected@file@percent }
\newlabel{approach}{{III}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Data preprocessing}{3}\protected@file@percent }
\newlabel{data_preprocessing}{{\unhbox \voidb@x \hbox {III-A}}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Hierarchical LSTMs}{3}\protected@file@percent }
\citation{he2013learning}
\citation{wang2018deep}
\citation{fan2019deep}
\citation{li2017software}
\citation{he2013learning}
\citation{jing2014dictionary}
\citation{chen2020different}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces A concrete example}}{4}\protected@file@percent }
\newlabel{fig1}{{2}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces GH-LSTMs}}{4}\protected@file@percent }
\newlabel{fig3}{{3}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-C}}Gated merge layer}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-D}}Model training}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {IV}Experiments settings}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Evaluated projects and datasets}{4}\protected@file@percent }
\citation{wang2018deep}
\citation{fan2019deep}
\citation{wang2018deep}
\citation{liang2019seml}
\citation{fan2019deep}
\citation{jiang2008techniques}
\citation{wang2018deep}
\citation{fan2019deep}
\citation{jing2014dictionary}
\citation{menzies2006data}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Dataset description}}{5}\protected@file@percent }
\newlabel{tab1}{{I}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Baseline setting}{5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces The selected AST nodes}}{5}\protected@file@percent }
\newlabel{tab2}{{II}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}}Evaluation}{5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}1}Metrics for non-effort-aware evaluation}{5}\protected@file@percent }
\citation{jiang2013personalized}
\citation{huang2017supervised}
\citation{kamei2012large}
\citation{wang2018deep}
\citation{zhou2018far}
\citation{huang2019revisiting}
\citation{yang2016effort}
\citation{wang2018deep}
\citation{zhou2018far}
\citation{kochhar2016practitioners}
\citation{mende2010effort}
\citation{wang2018deep}
\citation{zhou2018far}
\citation{huang2019revisiting}
\citation{yang2016effort}
\citation{fan2019deep}
\citation{liu2018connecting}
\citation{benjamini1995controlling}
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces Traditional features selected from PROMISE datasets}}{6}\protected@file@percent }
\newlabel{tab3}{{III}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}2}Metrics for effort-aware evaluation}{6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces An example of Alberg diagram}}{6}\protected@file@percent }
\newlabel{fig_popt}{{4}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}3}Win/Tie/Loss indicator}{6}\protected@file@percent }
\citation{wang2018deep}
\citation{fan2019deep}
\@writefile{lot}{\contentsline {table}{\numberline {IV}{\ignorespaces Mappings between the Cliff's delta values($|\delta |$) and their effective levels}}{7}\protected@file@percent }
\newlabel{tab_delta}{{IV}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-D}}Parameters setting}{7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {V}Experimental results}{7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-A}}Answer to RQ1: How does GH-LSTMs perform under non-effort-aware scenario?}{7}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {V}{\ignorespaces Hyper parameters for all LSTM networks}}{8}\protected@file@percent }
\newlabel{tab_parameters}{{V}{8}}
\@writefile{lot}{\contentsline {table}{\numberline {VI}{\ignorespaces $F-measure$ values of DBN, SCE, DP-AM and GH-LSTMs}}{8}\protected@file@percent }
\newlabel{tab_f}{{VI}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Overall $F-measure$ comparison of DBN, SCE, DP-AM and GH-LSTMs}}{8}\protected@file@percent }
\newlabel{fig_box_F-measure}{{5}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-B}}Answer to RQ2: How does GH-LSTMs perform under effort-aware scenario?}{8}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {VII}{\ignorespaces $PofB20$ scores of DBN, SCE, DP-AM and GH-LSTMs}}{9}\protected@file@percent }
\newlabel{tab_pof}{{VII}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Overall $PofB20$ comparison of DBN, SCE, DP-AM and GH-LSTMs}}{9}\protected@file@percent }
\newlabel{fig_box_PofB20}{{6}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Overall $IFA$ comparison of DBN, SCE, DP-AM and GH-LSTMs}}{9}\protected@file@percent }
\newlabel{fig_box_IFA}{{7}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Overall $P_{opt}$ comparison of DBN, SCE, DP-AM and GH-LSTMs}}{9}\protected@file@percent }
\newlabel{fig_box_Popt}{{8}{9}}
\@writefile{lot}{\contentsline {table}{\numberline {VIII}{\ignorespaces $IFA$ of DBN, SCE, DP-AM and GH-LSTMs}}{10}\protected@file@percent }
\newlabel{tab_ifa}{{VIII}{10}}
\@writefile{lot}{\contentsline {table}{\numberline {IX}{\ignorespaces $P_{opt}$ scores of DBN, SCE, DP-AM and GH-LSTMs}}{10}\protected@file@percent }
\newlabel{tab_popt}{{IX}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-C}}Answer to RQ3: How do external parameters affect the performance of GH-LSTMs?}{10}\protected@file@percent }
\citation{liang2019seml}
\citation{fan2019deep}
\citation{jureczko2010towards}
\citation{jureczko2010using}
\citation{wang2018deep}
\citation{liang2019seml}
\citation{fan2019deep}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces F-measure of GH-LSTMs under different embedding dimensions}}{11}\protected@file@percent }
\newlabel{fig_dimensions}{{9}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces F-measure of GH-LSTMs under different sizes of training sets}}{11}\protected@file@percent }
\newlabel{fig_size}{{10}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Threats to validity}{11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-A}}Internal validity}{11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-B}}External validity}{11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-C}}Construct validity}{11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-D}}Conclusion validity}{11}\protected@file@percent }
\citation{wang2018deep}
\citation{fan2019deep}
\citation{menzies2006data}
\citation{nagappan2010change}
\citation{nagappan2005use}
\citation{elish2008predicting}
\citation{wen2012systematic}
\citation{catal2009investigating}
\citation{elish2008predicting}
\citation{ryu2016value}
\citation{yang2015deep}
\citation{kamei2007effects}
\citation{liu2018connecting}
\citation{wang2018deep}
\citation{liang2019seml}
\citation{fan2019deep}
\bibstyle{IEEEtran}
\bibdata{IEEEtran}
\bibcite{catal2009systematic}{1}
\bibcite{jiang2013personalized}{2}
\bibcite{nam2014survey}{3}
\@writefile{toc}{\contentsline {section}{\numberline {VII}Related works}{12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VII-A}}Traditional software defect prediction}{12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VII-B}}Deep learning in software defect prediction}{12}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {VIII}Conclusion and future work}{12}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{References}{12}\protected@file@percent }
\bibcite{maurice1977elements}{4}
\bibcite{mccabe1976complexity}{5}
\bibcite{wang2018deep}{6}
\bibcite{zhou2018far}{7}
\bibcite{fan2019deep}{8}
\bibcite{li2017software}{9}
\bibcite{hinton2006fast}{10}
\bibcite{mikolov2013distributed}{11}
\bibcite{pennington2014glove}{12}
\bibcite{hochreiter1997long}{13}
\bibcite{liang2019seml}{14}
\bibcite{liu2018connecting}{15}
\bibcite{wang2018gated}{16}
\bibcite{ni2019empirical}{17}
\bibcite{he2013learning}{18}
\bibcite{jing2014dictionary}{19}
\bibcite{chen2020different}{20}
\bibcite{jiang2008techniques}{21}
\bibcite{menzies2006data}{22}
\bibcite{huang2017supervised}{23}
\bibcite{kamei2012large}{24}
\bibcite{huang2019revisiting}{25}
\bibcite{yang2016effort}{26}
\bibcite{kochhar2016practitioners}{27}
\bibcite{mende2010effort}{28}
\bibcite{benjamini1995controlling}{29}
\bibcite{jureczko2010towards}{30}
\bibcite{jureczko2010using}{31}
\bibcite{nagappan2010change}{32}
\bibcite{nagappan2005use}{33}
\bibcite{elish2008predicting}{34}
\bibcite{wen2012systematic}{35}
\bibcite{catal2009investigating}{36}
\bibcite{ryu2016value}{37}
\bibcite{yang2015deep}{38}
\bibcite{kamei2007effects}{39}
\@writefile{toc}{\contentsline {section}{Biographies}{14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Hao Wang}{14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Weiyuan Zhuang}{14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Xiaofang Zhang}{14}\protected@file@percent }
